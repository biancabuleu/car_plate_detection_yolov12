{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82baaf7a-2c89-476f-a68f-12ab9c6441a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed40efa-042f-4ef3-a6f9-d33250a764b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toate imaginile au fiÈ™iere .txt corespunzÄƒtoare.\n",
      "Toate fiÈ™ierele .txt au imagini corespunzÄƒtoare.\n",
      "\n",
      "NumÄƒrul total de imagini: 75\n",
      "NumÄƒrul total de fiÈ™iere .txt: 75\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "images_folder = '/Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-BUN/images/test'\n",
    "txt_folder = '/Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-BUN/labels/test'\n",
    "\n",
    "image_files = [f for f in os.listdir(images_folder) if f.endswith(('.jpg', '.jpeg'))]\n",
    "txt_files = [f for f in os.listdir(txt_folder) if f.endswith('.txt')]\n",
    "\n",
    "image_bases = set(os.path.splitext(f)[0] for f in image_files)\n",
    "txt_bases = set(os.path.splitext(f)[0] for f in txt_files)\n",
    "\n",
    "extra_txt = txt_bases - image_bases\n",
    "\n",
    "missing_txt = image_bases - txt_bases\n",
    "\n",
    "if missing_txt:\n",
    "    print(\"Imagini care nu au fiÈ™iere .txt corespunzÄƒtoare:\")\n",
    "    for item in missing_txt:\n",
    "        print(item)\n",
    "else:\n",
    "    print(\"Toate imaginile au fiÈ™iere .txt corespunzÄƒtoare.\")\n",
    "\n",
    "if extra_txt:\n",
    "    print(\"\\nFiÈ™iere .txt care nu au imagini corespunzÄƒtoare:\")\n",
    "    for item in extra_txt:\n",
    "        print(item)\n",
    "else:\n",
    "    print(\"Toate fiÈ™ierele .txt au imagini corespunzÄƒtoare.\")\n",
    "\n",
    "print(f\"\\nNumÄƒrul total de imagini: {len(image_files)}\")\n",
    "print(f\"NumÄƒrul total de fiÈ™iere .txt: {len(txt_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6166303-37d1-490b-9d7e-60adbb6f531d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.145 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.91 ðŸš€ Python-3.11.11 torch-2.6.0 CPU (Apple M3 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo12s.pt, data=/Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-BUN/config.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/opt/homebrew/runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n",
      " 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n",
      " 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 21        [14, 17, 20]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "YOLOv12s summary: 272 layers, 9,253,523 parameters, 9,253,507 gradients, 21.5 GFLOPs\n",
      "\n",
      "Transferred 685/691 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /opt/homebrew/runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-B\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /opt/homebrew/runs/detect/train/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/opt/homebrew/runs/detect/train\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G      1.353      2.396      1.152          5        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84     0.0679      0.619     0.0601     0.0346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       2/20         0G      1.366      1.185      1.115          2        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.377       0.69      0.656      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       3/20         0G      1.477      1.131      1.166          5        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84     0.0106      0.738     0.0131    0.00642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/20         0G      1.456      1.098      1.175          1        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.145      0.786      0.138      0.075\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       5/20         0G      1.372      1.002      1.123          4        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84     0.0129      0.504    0.00975    0.00544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       6/20         0G      1.275     0.8687      1.107          6        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.966      0.845      0.923      0.596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       7/20         0G       1.23     0.9003      1.071          5        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.889      0.833        0.9      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       8/20         0G      1.275     0.8507       1.08          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.857      0.893      0.916      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       9/20         0G      1.243     0.8487      1.074          5        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.959      0.917      0.965      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      10/20         0G      1.193     0.7951      1.045          6        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.987      0.889      0.955      0.597\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G      1.174     0.7265      1.029          2        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.999      0.905       0.96      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G      1.116     0.7084      1.012          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84          1      0.892      0.943      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      13/20         0G       1.09     0.6834      1.008          2        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.941      0.905      0.961      0.695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      14/20         0G      1.068      0.659     0.9809          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.985      0.929      0.976      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      15/20         0G      1.079     0.6367     0.9981          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.987      0.921      0.966      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      16/20         0G      1.049      0.616     0.9919          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.988       0.95      0.975      0.701\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      17/20         0G      1.006     0.5981     0.9712          2        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84          1      0.951      0.973       0.72\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      18/20         0G     0.9852     0.5886     0.9605          2        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.984      0.952      0.972      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      19/20         0G     0.9879     0.5642      0.956          3        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84          1      0.952      0.979      0.739\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      20/20         0G     0.9025      0.534     0.9374          1        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.998       0.94      0.981      0.737\n",
      "\n",
      "20 epochs completed in 3.074 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from /opt/homebrew/runs/detect/train/weights/last.pt, 18.9MB\n",
      "Optimizer stripped from /opt/homebrew/runs/detect/train/weights/best.pt, 18.9MB\n",
      "\n",
      "Validating /opt/homebrew/runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.91 ðŸš€ Python-3.11.11 torch-2.6.0 CPU (Apple M3 Pro)\n",
      "YOLOv12s summary (fused): 159 layers, 9,231,267 parameters, 0 gradients, 21.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84          1      0.952      0.979      0.739\n",
      "Speed: 0.5ms preprocess, 205.1ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1m/opt/homebrew/runs/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolo12s.pt\")\n",
    "\n",
    "results = model.train(\n",
    "    data=\"/Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-BUN/config.yaml\",\n",
    "    epochs=20    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11529d7a-1d88-4b24-aa0b-b28b3f73a294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/05/24 19:52:43] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/Beank/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/Beank/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/Beank/Library/Python/3.11/lib/python/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/Users/Beank/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "\n",
      "image 1/1 /Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-BUN/imagine.png: 384x640 1 car_plate, 95.4ms\n",
      "Speed: 2.2ms preprocess, 95.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-BUN/imagine.png: 384x640 1 car, 44.7ms\n",
      "Speed: 1.2ms preprocess, 44.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# === Config ===\n",
    "model_yolo_general = YOLO(\"yolo12n.pt\")\n",
    "model_yolo_plaque = YOLO(\"/content/best.pt\")\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "judete = [\n",
    "    'AB', 'AR', 'AG', 'BC', 'BH', 'BN', 'BR', 'BT', 'BV', 'BZ',\n",
    "    'CS', 'CL', 'CJ', 'CT', 'CV', 'DB', 'DJ', 'GL', 'GR', 'GJ',\n",
    "    'HR', 'HD', 'IL', 'IS', 'IF', 'MM', 'MH', 'MS', 'NT', 'OT',\n",
    "    'PH', 'SM', 'SJ', 'SB', 'SV', 'TR', 'TM', 'TL', 'VS', 'VL',\n",
    "    'VN', 'B'\n",
    "]\n",
    "\n",
    "judet_nume = {\n",
    "    'AB': 'Alba', 'AR': 'Arad', 'AG': 'ArgeÈ™', 'BC': 'BacÄƒu', 'BH': 'Bihor',\n",
    "    'BN': 'BistriÈ›a-NÄƒsÄƒud', 'BR': 'BrÄƒila', 'BT': 'BotoÈ™ani', 'BV': 'BraÈ™ov', 'BZ': 'BuzÄƒu',\n",
    "    'CS': 'CaraÈ™-Severin', 'CL': 'CÄƒlÄƒraÈ™i', 'CJ': 'Cluj', 'CT': 'ConstanÈ›a', 'CV': 'Covasna',\n",
    "    'DB': 'DÃ¢mboviÈ›a', 'DJ': 'Dolj', 'GL': 'GalaÈ›i', 'GR': 'Giurgiu', 'GJ': 'Gorj',\n",
    "    'HR': 'Harghita', 'HD': 'Hunedoara', 'IL': 'IalomiÈ›a', 'IS': 'IaÈ™i', 'IF': 'Ilfov',\n",
    "    'MM': 'MaramureÈ™', 'MH': 'MehedinÈ›i', 'MS': 'MureÈ™', 'NT': 'NeamÈ›', 'OT': 'Olt',\n",
    "    'PH': 'Prahova', 'SM': 'Satu Mare', 'SJ': 'SÄƒlaj', 'SB': 'Sibiu', 'SV': 'Suceava',\n",
    "    'TR': 'Teleorman', 'TM': 'TimiÈ™', 'TL': 'Tulcea', 'VS': 'Vaslui', 'VL': 'VÃ¢lcea',\n",
    "    'VN': 'Vrancea', 'B': 'BucureÈ™ti'\n",
    "}\n",
    "\n",
    "coco_labels = {\n",
    "    0: \"background\", 1: \"bicycle\", 2: \"car\", 3: \"motorcycle\", 4: \"airplane\",\n",
    "    5: \"bus\", 6: \"train\", 7: \"truck\", 8: \"boat\", 9: \"traffic light\"\n",
    "}\n",
    "\n",
    "def este_numar_romanesc(text):\n",
    "    text = text.replace(\" \", \"\").upper()\n",
    "    if len(text) < 2:\n",
    "        return False\n",
    "    prefix = text[:2] if text[:2] in judete else text[:1]\n",
    "    rest = text[len(prefix):]\n",
    "    return prefix in judete and (re.match(r'\\d{6}$', rest) or re.match(r'\\d{2,3}[A-Z]{1,3}$', rest))\n",
    "\n",
    "def detect_license_plates(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    results_plate = model_yolo_plaque(image_path)\n",
    "    results_general = model_yolo_general(image_path)\n",
    "\n",
    "    general_boxes = results_general[0].boxes.xyxy.cpu().numpy()\n",
    "    general_classes = results_general[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "    plate_count = 0\n",
    "\n",
    "    for result in results_plate:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            plate_crop = image[y1:y2, x1:x2].copy()\n",
    "            ocr_result = ocr.ocr(plate_crop, cls=True)\n",
    "            plate_count += 1\n",
    "\n",
    "            texts = []\n",
    "            confidences = []\n",
    "            country_text = \"\"\n",
    "            plate_texts = []\n",
    "\n",
    "            if ocr_result:\n",
    "                for entry in ocr_result:\n",
    "                    if not entry:\n",
    "                        continue\n",
    "                    for detection in entry:\n",
    "                        if not detection:\n",
    "                            continue\n",
    "                        bbox, (text, confidence) = detection\n",
    "                        print(text)\n",
    "                        text_clean = re.sub(r\"[.\\-,'\\s]\", \"\", text.upper())\n",
    "\n",
    "                        if confidence < 0.6:\n",
    "                            continue\n",
    "                        if text_clean == \"RO\" and not country_text:\n",
    "                            country_text = \"RO\"\n",
    "                            plate_texts.append(\"RO\")\n",
    "                            texts.append(text_clean)\n",
    "                            confidences.append(confidence)\n",
    "                        else:\n",
    "                            plate_texts.append(text_clean)\n",
    "                            texts.append(text_clean)\n",
    "                            confidences.append(confidence)\n",
    "                            if este_numar_romanesc(text_clean):\n",
    "                                print(f\"[INFO] Format romÃ¢nesc detectat: {text_clean}. Oprire OCR pentru aceastÄƒ plÄƒcuÈ›Äƒ.\")\n",
    "                                break\n",
    "\n",
    "            full_plate_text = \"\".join(plate_texts)\n",
    "            avg_confidence = sum(confidences) / len(confidences) if confidences else 0\n",
    "\n",
    "            is_romanian = (country_text == \"RO\") or (full_plate_text and este_numar_romanesc(full_plate_text))\n",
    "            if is_romanian and \"RO\" not in full_plate_text:\n",
    "                country_text = \"RO\"\n",
    "                full_plate_text = \"RO\" + full_plate_text\n",
    "\n",
    "            country_display = country_text\n",
    "            plate_display = full_plate_text.replace(\"RO\", \"\") if country_text == \"RO\" else full_plate_text\n",
    "\n",
    "            object_label = \"unknown object\"\n",
    "            for obj_box, obj_cls in zip(general_boxes, general_classes):\n",
    "                ox1, oy1, ox2, oy2 = map(int, obj_box)\n",
    "                if x1 >= ox1 and y1 >= oy1 and x2 <= ox2 and y2 <= oy2:\n",
    "                    object_label = coco_labels.get(int(obj_cls), f\"Class {int(obj_cls)}\")\n",
    "                    break\n",
    "\n",
    "            judet_text = \"\"\n",
    "            prefix = plate_display[:2] if plate_display[:2] in judet_nume else plate_display[:1]\n",
    "            if prefix in judet_nume:\n",
    "                judet_text = f\" - judet: {judet_nume[prefix]}\"\n",
    "\n",
    "            final_text = \"\"\n",
    "            if country_display or plate_display:\n",
    "                final_text = f\"{country_display} - {plate_display} ({avg_confidence * 100:.1f}%)\"\n",
    "                final_text += \" - romanian number\" if is_romanian else \" - foreign registration number\"\n",
    "                final_text += judet_text\n",
    "                final_text += f\" | Obiect: {object_label}\"\n",
    "\n",
    "            color = (0, 255, 0) if is_romanian else (0, 0, 255)\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 3)\n",
    "\n",
    "            h, w = image.shape[:2]\n",
    "            (text_width, text_height), _ = cv2.getTextSize(final_text, cv2.FONT_HERSHEY_SIMPLEX, 3, 12)\n",
    "            x = w - text_width - 20\n",
    "            y = h - 20\n",
    "\n",
    "            cv2.putText(image, final_text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 255), 12)\n",
    "            cv2.putText(image, final_text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 0), 12)\n",
    "\n",
    "            print(f\"\\n=== Plate {plate_count} ===\")\n",
    "            print(final_text if final_text else \"No valid text identified..\")\n",
    "\n",
    "            cv2.imwrite(f\"plate_{plate_count}.jpg\", plate_crop)\n",
    "\n",
    "    cv2.imwrite(\"car_plate.jpg\", image)\n",
    "\n",
    "detect_license_plates(\"/content/masina2.jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7462d7b2-ca2c-4628-912b-7a67c18df3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.91 ðŸš€ Python-3.11.11 torch-2.6.0 CPU (Apple M3 Pro)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-B\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         84      0.963       0.94      0.962      0.745\n",
      "Speed: 0.3ms preprocess, 125.8ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1m/opt/homebrew/runs/detect/val\u001b[0m\n",
      "==============YOLOV12N_FINAL===========\n",
      "Precision (mean): 0.963\n",
      "Recall (mean): 0.940\n",
      "F1 Score (mean): 0.952\n",
      "mAP@0.5: 0.962\n",
      "mAP@0.5:0.95: 0.745\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-BUN/yolo12n_15epochs_final/weights/best.pt\")\n",
    "metrics = model.val(data=\"/Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-BUN/config.yaml\", split='val', conf=0.30)\n",
    "\n",
    "print(\"==============YOLOV12N_FINAL===========\")\n",
    "\n",
    "print(f\"Precision (mean): {metrics.box.mp:.3f}\")\n",
    "print(f\"Recall (mean): {metrics.box.mr:.3f}\")\n",
    "print(f\"F1 Score (mean): {metrics.box.f1.mean():.3f}\")\n",
    "print(f\"mAP@0.5: {metrics.box.map50:.3f}\")\n",
    "print(f\"mAP@0.5:0.95: {metrics.box.map:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f365e-717f-4380-a3f7-a7be7f546242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.91 ðŸš€ Python-3.11.11 torch-2.6.0 CPU (Apple M3 Pro)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-B\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         75         77      0.974      0.961      0.979      0.769\n",
      "Speed: 0.4ms preprocess, 225.5ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1m/opt/homebrew/runs/detect/val2\u001b[0m\n",
      "==============YOLOV12n_FINAL===========\n",
      "Precision (mean): 0.974\n",
      "Recall (mean): 0.961\n",
      "F1 Score (mean): 0.967\n",
      "mAP@0.5: 0.979\n",
      "mAP@0.5:0.95: 0.769\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"/Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-BUN/yolo11s_20epochs/weights/best.pt\")\n",
    "\n",
    "metrics = model.val(data=\"/Users/Beank/Desktop/doctorat-dizertatie/algorithm/yolo-doctorat-BUN/config.yaml\", split='test', conf=0.50, iou=0.5)  # sau 'val' dacÄƒ vrei\n",
    "\n",
    "print(\"==============YOLOV12n_FINAL===========\")\n",
    "\n",
    "print(f\"Precision (mean): {metrics.box.mp:.3f}\")\n",
    "print(f\"Recall (mean): {metrics.box.mr:.3f}\")\n",
    "print(f\"F1 Score (mean): {metrics.box.f1.mean():.3f}\")\n",
    "print(f\"mAP@0.5: {metrics.box.map50:.3f}\")\n",
    "print(f\"mAP@0.5:0.95: {metrics.box.map:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6bdc3-1db1-4ace-a73f-75b211079d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb45e5-42ef-4096-bcfa-bc490ff5449e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
